{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Use stacked images (3D) and Efficientnet3D model\n\nAcknowledgements:\n\n- https://www.kaggle.com/ihelon/brain-tumor-eda-with-animations-and-modeling\n- https://www.kaggle.com/furcifer/torch-efficientnet3d-for-mri-no-train\n- https://github.com/shijianjian/EfficientNet-PyTorch-3D\n    \n    \nUse models with only one MRI type, then ensemble the 4 models \n","metadata":{}},{"cell_type":"code","source":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport collections\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport imgaug as ia\nimport imgaug.augmenters as iaa","metadata":{"papermill":{"duration":1.048295,"end_time":"2021-07-14T20:26:46.309722","exception":false,"start_time":"2021-07-14T20:26:45.261427","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-27T16:21:02.562286Z","iopub.execute_input":"2022-02-27T16:21:02.562663Z","iopub.status.idle":"2022-02-27T16:21:05.841172Z","shell.execute_reply.started":"2022-02-27T16:21:02.562585Z","shell.execute_reply":"2022-02-27T16:21:05.840149Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"dataset = 'test'\nseries_names = ['FLAIR','T1w','T1wCE','T2w']\ndirectory = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'\n# This function gets called by get_middle_images function\n#Returns the list of all images present in a particular series(modality) of a given patient\ndef get_series_list(dataset, study_id, series_name):\n\n    series_list = []\n\n    for subdirs, dirs, files in os.walk(directory + '/' + dataset + '/' + study_id + \"/\" + series_name):\n        series_list = os.listdir(directory + '/' + dataset + '/' + study_id + '/' + series_name)\n    return series_list\n\n\ndef get_middle_images(study_id):\n    \n    middle_images = []\n    \n    # Iterate through each of the four series directories and get the files \n    for ser in series_names:\n        series_files = get_series_list(dataset, study_id, ser)\n        series_df = pd.DataFrame(columns = ['image','instance_number'])\n\n        # Get the DICOM InstanceNumber tag to order the images since we can't rely on the filenames to be in order\n        for s in series_files:\n            img = pydicom.dcmread(directory + \"/\" + dataset + \"/\" + study_id + \"/\" + ser + \"/\" + s)\n            series_df.loc[len(series_df.index)] = [s, img[0x0020,0x0013].value]\n            \n            # 0x0020,0x0013 refers to image number, comes from Dicom dictionary (https://imagej.nih.gov/nih-image/download/nih-image_spin-offs/NucMed_Image/DICOM%20Dictionary)\n \n        series_df['instance_number'] = pd.to_numeric(series_df['instance_number'])\n\n        # Sort the image list by InstanceNumber\n        series_df = series_df.sort_values(by=['instance_number'])\n        \n        # Find the image in the middle of the list\n        middle_index = int(series_df.shape[0] / 2)\n        middle_image = series_df.iloc[middle_index]['image']\n\n        middle_images.append(ser + \"/\" + middle_image)\n\n    return middle_images\n\n\n#Given the image orientation, returns the image plane \ndef get_image_plane(loc):\n\n    row_x = round(loc[0])\n    row_y = round(loc[1])\n    row_z = round(loc[2])\n    col_x = round(loc[3])\n    col_y = round(loc[4])\n    col_z = round(loc[5])\n\n    if row_x == 1 and row_y == 0 and col_x == 0 and col_y == 0:\n        return \"Coronal\"\n\n    if row_x == 0 and row_y == 1 and col_x == 0 and col_y == 0:\n        return \"Sagittal\"\n\n    return 'Axial'\n\n#for getting the image plane corresponding to the middle images of all the series of a particular patient\ndef plot_images(images, image_id):\n    result = []\n    for img in images:\n        image = pydicom.dcmread(directory + \"/\" + dataset + \"/\" + image_id + \"/\" + img)\n        # 0x0020,0x0037 in dicom dictionary refers to \"Image Orientation (Patient)\"\n        image_orientation_patient = image[0x0020,0x0037]\n        plane = get_image_plane(image_orientation_patient)\n        result.append(plane)\n        \n    return result\n\ndf = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\n# x:05 converts columns to have a fixed width(to include leading zeroes)\ndf['BraTS21ID'] = df['BraTS21ID'].apply(lambda x: f\"{x:05}\")\nhey = df['BraTS21ID'].apply(lambda x: plot_images(get_middle_images(x), x))\nheyhey = pd.DataFrame.from_dict(dict(zip(hey.index, hey.values))).T\ndf[['FLAIR', 'T1w', 'T1wCE', 'T2w']] = 0\ndf[['FLAIR', 'T1w', 'T1wCE', 'T2w']] = heyhey","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:21:05.845988Z","iopub.execute_input":"2022-02-27T16:21:05.848088Z","iopub.status.idle":"2022-02-27T16:29:23.034567Z","shell.execute_reply.started":"2022-02-27T16:21:05.848050Z","shell.execute_reply":"2022-02-27T16:29:23.033735Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_directory = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'\npytorch3dpath = \"../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D\"\n    \nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nangle_types = ['Axial', 'Coronal', 'Sagittal']\nSIZE = 256\nNUM_IMAGES = 64\n\nsys.path.append(pytorch3dpath)\nfrom efficientnet_pytorch_3d import EfficientNet3D","metadata":{"lines_to_end_of_cell_marker":2,"lines_to_next_cell":2,"papermill":{"duration":0.05565,"end_time":"2021-07-14T20:26:46.486521","exception":false,"start_time":"2021-07-14T20:26:46.430871","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-27T16:29:23.037066Z","iopub.execute_input":"2022-02-27T16:29:23.037564Z","iopub.status.idle":"2022-02-27T16:29:23.062967Z","shell.execute_reply.started":"2022-02-27T16:29:23.037526Z","shell.execute_reply":"2022-02-27T16:29:23.062274Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Functions to load images","metadata":{}},{"cell_type":"code","source":"from pydicom.pixel_data_handlers import apply_voi_lut\ndef load_dicom_image(path, img_size=SIZE):\n    dicom = pydicom.read_file(path)\n    data = apply_voi_lut(dicom.pixel_array, dicom)\n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n\n    files = sorted(glob.glob(f\"{data_directory}/{split}/{scan_id}/{mri_type}/*.dcm\"))\n    \n    middle = len(files)//2\n    num_imgs2 = num_imgs//2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f) for f in files[p1:p2]]).T \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n            \n    return np.expand_dims(img3d,0)\n\na = load_dicom_images_3d(\"00000\")\na.shape","metadata":{"papermill":{"duration":0.035761,"end_time":"2021-07-14T20:26:46.726756","exception":false,"start_time":"2021-07-14T20:26:46.690995","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-27T16:29:23.064529Z","iopub.execute_input":"2022-02-27T16:29:23.064878Z","iopub.status.idle":"2022-02-27T16:29:24.167658Z","shell.execute_reply.started":"2022-02-27T16:29:23.064843Z","shell.execute_reply":"2022-02-27T16:29:24.166800Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(1, 256, 256, 64)"},"metadata":{}}]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(42)","metadata":{"papermill":{"duration":0.668331,"end_time":"2021-07-14T20:27:48.114522","exception":false,"start_time":"2021-07-14T20:27:47.446191","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-27T16:29:24.169061Z","iopub.execute_input":"2022-02-27T16:29:24.169436Z","iopub.status.idle":"2022-02-27T16:29:24.243554Z","shell.execute_reply.started":"2022-02-27T16:29:24.169394Z","shell.execute_reply":"2022-02-27T16:29:24.242830Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Model and training classes","metadata":{}},{"cell_type":"code","source":"class Dataset(torch_data.Dataset):\n    def __init__(self, paths, targets=None, mri_type=None, label_smoothing=0.01, split=\"train\"):\n        self.paths = paths\n        self.targets = targets\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.split = split\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        scan_id = self.paths[index]\n        if self.targets is None:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=self.split)\n        else:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=\"train\")\n\n        if self.targets is None:\n            return {\"X\": torch.tensor(data).float(), \"id\": scan_id}\n        else:\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}\n","metadata":{"papermill":{"duration":0.634322,"end_time":"2021-07-14T20:27:50.594701","exception":false,"start_time":"2021-07-14T20:27:49.960379","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-27T16:29:24.244824Z","iopub.execute_input":"2022-02-27T16:29:24.245147Z","iopub.status.idle":"2022-02-27T16:29:24.256032Z","shell.execute_reply.started":"2022-02-27T16:29:24.245113Z","shell.execute_reply":"2022-02-27T16:29:24.255219Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","metadata":{"papermill":{"duration":0.825458,"end_time":"2021-07-14T20:27:55.604161","exception":false,"start_time":"2021-07-14T20:27:54.778703","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-27T16:29:24.257404Z","iopub.execute_input":"2022-02-27T16:29:24.257834Z","iopub.status.idle":"2022-02-27T16:29:24.265499Z","shell.execute_reply.started":"2022-02-27T16:29:24.257788Z","shell.execute_reply":"2022-02-27T16:29:24.264658Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Predict function","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"lines_to_next_cell":2,"papermill":{"duration":447.387602,"end_time":"2021-07-14T20:35:26.110421","exception":false,"start_time":"2021-07-14T20:27:58.722819","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-27T16:29:24.267937Z","iopub.execute_input":"2022-02-27T16:29:24.268283Z","iopub.status.idle":"2022-02-27T16:29:24.275389Z","shell.execute_reply.started":"2022-02-27T16:29:24.268248Z","shell.execute_reply":"2022-02-27T16:29:24.274540Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"modeldict = {\n    'FLAIR': {\n        'Axial': '../input/lotsof3defficientnets/FLAIR-Axial-e6-loss0.680.pth',\n        'Coronal': '../input/lotsof3defficientnets/FLAIR-Coronal-e10-loss0.635.pth',\n        'Sagittal': '../input/lotsof3defficientnets/FLAIR-Sagittal-e1-loss0.696.pth',\n    },\n    \n    'T1w': {\n        'Axial': '../input/lotsof3defficientnets/T1w-Axial-e3-loss0.693.pth',\n        'Coronal': '../input/lotsof3defficientnets/T1w-Coronal-e3-loss0.697.pth',\n        'Sagittal': '../input/lotsof3defficientnets/T1wCE-Sagittal-e1-loss0.695.pth',\n    },\n    \n    'T1wCE': {\n        'Axial': '../input/lotsof3defficientnets/T1wCE-Axial-e3-loss0.693.pth',\n        'Coronal': '../input/lotsof3defficientnets/T1wCE-Coronal-e10-loss0.683.pth',\n        'Sagittal': '../input/lotsof3defficientnets/T1wCE-Sagittal-e1-loss0.695.pth',\n    },\n    \n    'T2w': {\n        'Axial': '../input/lotsof3defficientnets/T2w-Axial-e5-loss0.673.pth',\n        'Coronal': '../input/lotsof3defficientnets/T2w-Coronal-e1-loss0.693.pth',\n        'Sagittal': '../input/lotsof3defficientnets/T2w-Sagittal-e10-loss0.599.pth',\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:29:24.278506Z","iopub.execute_input":"2022-02-27T16:29:24.278942Z","iopub.status.idle":"2022-02-27T16:29:24.286367Z","shell.execute_reply.started":"2022-02-27T16:29:24.278916Z","shell.execute_reply":"2022-02-27T16:29:24.285525Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def predict(modelfile, df, mri_type, angle_type, split):\n    print(\"Predict:\", modelfile, mri_type, angle_type, df.shape)\n    \n    df = df[df[mri_type]==angle_type]\n    df.loc[:,\"MRI_Type\"] = mri_type\n    data_retriever = Dataset(\n        df.BraTS21ID.values, \n        mri_type=df[\"MRI_Type\"].values,\n        split=split\n    )\n\n    data_loader = torch_data.DataLoader(\n        data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=2,\n    )\n   \n    model = Model()\n    model.to(device)\n    \n    checkpoint = torch.load(modelfile, map_location=device)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    y_pred = []\n    ids = []\n\n    for e, batch in enumerate(data_loader,1):\n        print(f\"{e}/{len(data_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            if tmp_pred.size == 1:\n                y_pred.append(tmp_pred)\n            else:\n                y_pred.extend(tmp_pred.tolist())\n            ids.extend(batch[\"id\"])\n#             ids.extend(batch[\"id\"])\n            \n    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n    preddf = preddf.set_index(\"BraTS21ID\")\n    return preddf","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:29:24.287645Z","iopub.execute_input":"2022-02-27T16:29:24.287983Z","iopub.status.idle":"2022-02-27T16:29:24.298212Z","shell.execute_reply.started":"2022-02-27T16:29:24.287951Z","shell.execute_reply":"2022-02-27T16:29:24.297281Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble for submission","metadata":{}},{"cell_type":"code","source":"submission = df.copy()\nsubmission[\"MGMT_value\"] = 0\nfor mtype in mri_types:\n    for atype in angle_types:\n        m = modeldict[mtype][atype]\n        try:\n            pred = predict(m, submission, mtype, atype, split=\"test\")\n        except ValueError:\n            continue\n        submission = pd.merge(submission, pred, how='left', on='BraTS21ID').fillna(0)\n        submission['MGMT_value'] = submission['MGMT_value_x'] + submission['MGMT_value_y']\n        submission = submission[['BraTS21ID', 'MGMT_value', 'FLAIR', 'T1w', 'T1wCE', 'T2w']]\n\nsubmission = submission[['BraTS21ID', 'MGMT_value']]\nsubmission[\"MGMT_value\"] /= len(mri_types)","metadata":{"papermill":{"duration":0.990911,"end_time":"2021-07-14T20:35:30.482254","exception":false,"start_time":"2021-07-14T20:35:29.491343","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-27T16:29:24.299733Z","iopub.execute_input":"2022-02-27T16:29:24.300179Z","iopub.status.idle":"2022-02-27T16:29:28.901165Z","shell.execute_reply.started":"2022-02-27T16:29:24.300140Z","shell.execute_reply":"2022-02-27T16:29:28.899339Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Predict: ../input/lotsof3defficientnets/FLAIR-Axial-e6-loss0.680.pth FLAIR Axial (87, 6)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.obj[key] = value\n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value, pi)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-c65a047438ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodeldict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-63c1bf8c004c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(modelfile, df, mri_type, angle_type, split)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/lotsof3defficientnets/FLAIR-Axial-e6-loss0.680.pth'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/lotsof3defficientnets/FLAIR-Axial-e6-loss0.680.pth'","output_type":"error"}]},{"cell_type":"markdown","source":"<!-- submission.to_csv(\"submission.csv\", index=False) -->","metadata":{}},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:29:28.902365Z","iopub.status.idle":"2022-02-27T16:29:28.903085Z"},"trusted":true},"execution_count":null,"outputs":[]}]}